PROBLEM WORD PROCESSING
You have been tasked to help develop a library of code to be used by a word processing program.

What youâ€™ll build:
You will apply what you learned about processing collections of data, using lambda functions and list (and dictionary) comprehensions to process collections of words in various ways.

You will learn:

	- How to use lambda functions, map(), filter() and reduce() functions to transform and filter.

	- How to use list and dictionary comprehensions to generate new collections of data.

TIP	
Remember to use TDD when implementing your solutions.


Use Case:
The word processing program needs to offer functionality that helps determine linguistic complexity. This data will eventually be input to an AI system that will use it to suggest ways to improve the text.

The expected features includes: * transform all the words to a list of lowercase strings for further processing * determine all the words of longer than a specified length, in order to get a degree of complexity of the text * determine the spread of word lengths (i.e. how many words of each length appears) * count how many times each alphabet character appears in a list of words

Goal:
You need to implement functions for each of these features. The function signatures has already been defined in word_processor.py, as the word processor program expects these functions. You are free to implement additional helper functions.



INSTRUCTIONS

> STEP 1 Transform to lowercase list
Typically text entered in a word processor will contain a mixture of capital (upper) and lower case characters. It is also provided as a single string.
You will need to convert a string representing the text from the word processor to a list of lowercase strings.

Implement the function convert_to_word_list(text) so that:
	- it splits the text string at spaces, commas ,, semi-colons ;, question marks ? and points . into a list of words.

	- it can make use of the split(delimiters, text) function already defined in word_processor.py

	- each word must be converted to lower case.

	- implement your tests in test_words.py, in the same directory as word_processor.py (and remember to add tests for future steps as well)

	As an example:

	words = convert_to_word_list('These are indeed interesting, an obvious understatement, times. What say you?')
	print(words)
	Should render:

	['these','are','indeed','interesting','an','obvious','understatement','times','what','say','you']


> STEP 2 Filter words on length
Using a lot of long words might indicate a more complex writing style.

	- Implement the function words_longer_than(length, text) so that:
	it takes a string of text as input

	- it returns a list of words in the text that is longer than the specified length (i.e. has more than length characters)

	As an example:

	words = words_longer_than(10, 'These are indeed interesting, an obvious understatement, times. What say you?')
	print(words)
	Should render:

	['interesting','understatement']


> STEP 3 Spread of word lengths
It is also very interesting to look at the spread of word lengths in a text, i.e. how many words occur of each length. You can image a curve being drawn from this data, where most words would be a short to average length, with a few words longer.

You need to implement words_lengths_map(text) that:
	- it takes a string of text as input.

	- it must return a dictionary (dict) that maps a word length, e.g. 3, to the number of words in the text of that length.

	As an example:

	word_lengths = words_lengths_map('These are indeed interesting, an obvious understatement, times. What say you?')
	print(word_lengths)
	Should render:

	{2: 1, 3: 3, 4: 1, 5: 2, 6: 1, 7: 1, 11: 1, 14: 1}


> STEP 4 Count the letters
The planned AI system will do advanced analytics using the number of times specific alphabet letters occur in a text.

Implement the function letters_count_map(text) that:
	- it takes a string of text as input.

	- it must return a dictionary that maps each alphabet letter a to z to the number of times that letter occurs in the text.

	As an example:

	char_count = letters_count_map('These are indeed interesting, an obvious understatement, times. What say you?')
	print(char_count)
	Should render:

	{'a':5, 'b': 1, 'c':0, 'd': 3, 'e': 11, 'f': 0, 'g': 1, 'h': 2, 'i': 5, 'j': 0, 'k': 0, 'l': 0, 'm': 2, 'n': 6, 'o': 3, 'p': 0, 'q': 0, 'r': 3, 's': 6, 't': 8, 	'u': 3, 'v': 1, 'w': 1, 'x': 0, 'y': 2, 'z': 0}


> STEP 5 Reduce to highest occurrence
You also need to indicate the alphabet letter that occurs the most in a given text.

Implement the function most_used_character(text) to:
	- reuse letters_count_map to get the count of letters

	- reduce that to the letter that occurs the most, and return that letter.

	- for empty text, or text that does not contain any alphabet characters, return None

	As an example:

	popular_char = most_used_character('These are indeed interesting, an obvious understatement, times. What say you?')
	print(popular_char)
	Should render:

	e

